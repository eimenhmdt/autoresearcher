{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udd16\ud83e\uddea AutoResearcher","text":"<p>\u26a1 Automating scientific workflows with AI \u26a1</p> <p> </p>"},{"location":"#what-is-autoresearcher","title":"What is AutoResearcher?","text":"<p>AutoResearcher is an open-source Python package that combines AI models and external knowledge sources to automate scientific workflows. It is designed to help researchers and scientists to speed up their research process and to make it more efficient.</p> <p>The project is a very early prototype and is still under development. Currently, it is limited to conducting literature reviews. The vision, however, is to create a tool that can conduct actual scientific discovery on autopilot.</p> <p>If this vision excites you, please consider contributing to the project. You can start by joining the Discord server and discussing your ideas with the community.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install the package using pip:</p> <pre><code>pip install autoresearcher\n</code></pre>"},{"location":"#setting-environment-variables","title":"Setting Environment Variables","text":"<p>Before using the package, you need to set the following environment variables:</p> <ul> <li><code>OPENAI_API_KEY</code>: Your OpenAI API key for accessing the GPT-based AI models.</li> <li><code>EMAIL</code>: An email address of your choice (used to identify your API requests for getting citations).</li> </ul> <p>You can set the environment variables in your operating system or in your Python script using the <code>os</code> module:</p> <pre><code>import os\n\nos.environ[\"OPENAI_API_KEY\"] = \"&lt;your_openai_api_key&gt;\"\nos.environ[\"EMAIL\"] = \"&lt;your_email&gt;\"\n</code></pre> <p>Replace  and  with your actual API key and email address."},{"location":"#usage","title":"Usage","text":"<ol> <li>Import the literature_review function from the package:</li> </ol> <pre><code>from autoresearcher import literature_review\n</code></pre> <ol> <li>Set your research question as a string:</li> </ol> <pre><code>research_question = \"What is the best way to train a neural network?\"\n</code></pre> <ol> <li>Create a literature_review instance with your research question and execute it:</li> </ol> <pre><code>researcher = literature_review(research_question)\n</code></pre> <p>You can also pass an output file name as a .txt file:</p> <pre><code>researcher = literature_review(research_question, output_file=\"my_literature_review.txt\")\n</code></pre> <p>This will generate a literature review based on the research question.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please feel free to submit issues or create pull requests. Let's take upgrade science together! \ud83d\ude80</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p> <p>Made with \u2615 by @eimenhamedat</p>"},{"location":"reference/data_sources/","title":"Data sources","text":""},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.wikipedia_loader.WikipediaLoader","title":"<code>WikipediaLoader</code>","text":"<p>               Bases: <code>BaseWebAPIDataLoader</code></p> Source code in <code>autoresearcher/data_sources/web_apis/wikipedia_loader.py</code> <pre><code>class WikipediaLoader(BaseWebAPIDataLoader):\n    def __init__(self):\n        super().__init__(\"https://en.wikipedia.org/w/api.php\")\n\n    def fetch_data(self, search_query, results=10, language=\"en\"):\n        \"\"\"\n        Fetches data from the Wikipedia API.\n        Args:\n          search_query (str): The query to search for.\n          results (int, optional): The maximum number of results to return. Defaults to 10.\n          language (str, optional): The language to search in. Defaults to \"en\".\n        Returns:\n          list: A list of dictionaries containing the data for each result.\n        Raises:\n          wikipedia.exceptions.DisambiguationError: If the search query returns a disambiguation page.\n        Examples:\n          &gt;&gt;&gt; loader = WikipediaLoader()\n          &gt;&gt;&gt; loader.fetch_data(\"Python\")\n          [\n            {\n              \"title\": \"Python (programming language)\",\n              \"url\": \"https://en.wikipedia.org/wiki/Python_(programming_language)\",\n              \"summary\": \"Python is an interpreted, high-level, general-purpose programming language.\",\n              \"content\": \"Python is an interpreted, high-level, general-purpose programming language...\",\n              \"categories\": [\"Programming languages\"],\n              \"references\": [\"https://www.python.org/\"]\n            }\n          ]\n        \"\"\"\n        wikipedia.set_lang(language)\n        wikipedia.set_rate_limiting(True)\n\n        search_results = wikipedia.search(search_query, results=results)\n        data = []\n\n        for result in search_results:\n            try:\n                page = wikipedia.page(result)\n                data.append(\n                    {\n                        \"title\": page.title,\n                        \"url\": page.url,\n                        \"summary\": page.summary,\n                        \"content\": page.content,\n                        \"categories\": page.categories,\n                        \"references\": page.references,\n                    }\n                )\n            except wikipedia.exceptions.DisambiguationError as e:\n                # Handle disambiguation pages by selecting the first option\n                if e.options:\n                    page = wikipedia.page(e.options[0])\n                    data.append(\n                        {\n                            \"title\": page.title,\n                            \"url\": page.url,\n                            \"summary\": page.summary,\n                            \"content\": page.content,\n                            \"categories\": page.categories,\n                            \"references\": page.references,\n                        }\n                    )\n            except wikipedia.exceptions.PageError:\n                # Skip pages that cannot be found\n                continue\n\n        return data\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.wikipedia_loader.WikipediaLoader.fetch_data","title":"<code>fetch_data(search_query, results=10, language='en')</code>","text":"<p>Fetches data from the Wikipedia API. Args:   search_query (str): The query to search for.   results (int, optional): The maximum number of results to return. Defaults to 10.   language (str, optional): The language to search in. Defaults to \"en\". Returns:   list: A list of dictionaries containing the data for each result. Raises:   wikipedia.exceptions.DisambiguationError: If the search query returns a disambiguation page. Examples:</p> <p>loader = WikipediaLoader() loader.fetch_data(\"Python\")   [     {       \"title\": \"Python (programming language)\",       \"url\": \"https://en.wikipedia.org/wiki/Python_(programming_language)\",       \"summary\": \"Python is an interpreted, high-level, general-purpose programming language.\",       \"content\": \"Python is an interpreted, high-level, general-purpose programming language...\",       \"categories\": [\"Programming languages\"],       \"references\": [\"https://www.python.org/\"]     }   ]</p> Source code in <code>autoresearcher/data_sources/web_apis/wikipedia_loader.py</code> <pre><code>def fetch_data(self, search_query, results=10, language=\"en\"):\n    \"\"\"\n    Fetches data from the Wikipedia API.\n    Args:\n      search_query (str): The query to search for.\n      results (int, optional): The maximum number of results to return. Defaults to 10.\n      language (str, optional): The language to search in. Defaults to \"en\".\n    Returns:\n      list: A list of dictionaries containing the data for each result.\n    Raises:\n      wikipedia.exceptions.DisambiguationError: If the search query returns a disambiguation page.\n    Examples:\n      &gt;&gt;&gt; loader = WikipediaLoader()\n      &gt;&gt;&gt; loader.fetch_data(\"Python\")\n      [\n        {\n          \"title\": \"Python (programming language)\",\n          \"url\": \"https://en.wikipedia.org/wiki/Python_(programming_language)\",\n          \"summary\": \"Python is an interpreted, high-level, general-purpose programming language.\",\n          \"content\": \"Python is an interpreted, high-level, general-purpose programming language...\",\n          \"categories\": [\"Programming languages\"],\n          \"references\": [\"https://www.python.org/\"]\n        }\n      ]\n    \"\"\"\n    wikipedia.set_lang(language)\n    wikipedia.set_rate_limiting(True)\n\n    search_results = wikipedia.search(search_query, results=results)\n    data = []\n\n    for result in search_results:\n        try:\n            page = wikipedia.page(result)\n            data.append(\n                {\n                    \"title\": page.title,\n                    \"url\": page.url,\n                    \"summary\": page.summary,\n                    \"content\": page.content,\n                    \"categories\": page.categories,\n                    \"references\": page.references,\n                }\n            )\n        except wikipedia.exceptions.DisambiguationError as e:\n            # Handle disambiguation pages by selecting the first option\n            if e.options:\n                page = wikipedia.page(e.options[0])\n                data.append(\n                    {\n                        \"title\": page.title,\n                        \"url\": page.url,\n                        \"summary\": page.summary,\n                        \"content\": page.content,\n                        \"categories\": page.categories,\n                        \"references\": page.references,\n                    }\n                )\n        except wikipedia.exceptions.PageError:\n            # Skip pages that cannot be found\n            continue\n\n    return data\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.semantic_scholar_loader.SemanticScholarLoader","title":"<code>SemanticScholarLoader</code>","text":"<p>               Bases: <code>BaseWebAPIDataLoader</code></p> Source code in <code>autoresearcher/data_sources/web_apis/semantic_scholar_loader.py</code> <pre><code>class SemanticScholarLoader(BaseWebAPIDataLoader):\n    def __init__(self):\n        \"\"\"\n        Initializes the SemanticScholarLoader class.\n        Args:\n          None\n        Returns:\n          None\n        Notes:\n          Calls the superclass constructor with the SemanticScholar API URL.\n        \"\"\"\n        super().__init__(\"https://api.semanticscholar.org/graph/v1/paper/search\")\n\n    def fetch_data(self, search_query, limit=100, year_range=None):\n        \"\"\"\n        Fetches data from the SemanticScholar API.\n        Args:\n          search_query (str): The query to search for.\n          limit (int, optional): The maximum number of results to return. Defaults to 100.\n          year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None.\n        Returns:\n          list: A list of paper objects.\n        Examples:\n          &gt;&gt;&gt; fetch_data(\"machine learning\", limit=50, year_range=(2010, 2020))\n          [{...}, {...}, ...]\n        \"\"\"\n        params = {\n            \"query\": search_query,\n            \"limit\": limit,\n            \"fields\": \"title,url,abstract,authors,citationStyles,journal,citationCount,year,externalIds\",\n        }\n\n        if year_range is not None:\n            params[\"year\"] = year_range\n\n        data = self.make_request(\"\", params=params)\n        return data.get(\"data\", [])\n\n    def fetch_and_sort_papers(\n        self,\n        search_query,\n        limit=100,\n        top_n=20,\n        year_range=None,\n        keyword_combinations=None,\n        weight_similarity=0.5,\n    ):\n        \"\"\"\n        Fetches and sorts papers from the SemanticScholar API.\n        Args:\n          search_query (str): The query to search for.\n          limit (int, optional): The maximum number of results to return. Defaults to 100.\n          top_n (int, optional): The maximum number of results to return after sorting. Defaults to 20.\n          year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None.\n          keyword_combinations (list, optional): A list of keyword combinations to search for. Defaults to None.\n          weight_similarity (float, optional): The weight to give to the similarity score when sorting. Defaults to 0.5.\n        Returns:\n          list: A list of the top `top_n` paper objects sorted by combined score.\n        Examples:\n          &gt;&gt;&gt; fetch_and_sort_papers(\"machine learning\", limit=50, top_n=10, year_range=(2010, 2020))\n          [{...}, {...}, ...]\n        \"\"\"\n        papers = []\n        if keyword_combinations is None:\n            keyword_combinations = [search_query]\n\n        for combination in keyword_combinations:\n            papers.extend(self.fetch_data(combination, limit, year_range))\n\n        max_citations = max(papers, key=lambda x: x[\"citationCount\"])[\"citationCount\"]\n\n        for paper in papers:\n            similarity = jellyfish.jaro_similarity(search_query, paper[\"title\"])\n            normalized_citation_count = paper[\"citationCount\"] / max_citations\n            paper[\"combined_score\"] = (weight_similarity * similarity) + (\n                (1 - weight_similarity) * normalized_citation_count\n            )\n\n        sorted_papers = sorted(papers, key=lambda x: x[\"combined_score\"], reverse=True)\n\n        # deduplicate paper entries prior to taking top n results\n        sorted_dedup_papers = list(\n            {each_paper[\"paperId\"]: each_paper for each_paper in sorted_papers}.values()\n        )\n\n        return sorted_dedup_papers[:top_n]\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.semantic_scholar_loader.SemanticScholarLoader.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the SemanticScholarLoader class. Args:   None Returns:   None Notes:   Calls the superclass constructor with the SemanticScholar API URL.</p> Source code in <code>autoresearcher/data_sources/web_apis/semantic_scholar_loader.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the SemanticScholarLoader class.\n    Args:\n      None\n    Returns:\n      None\n    Notes:\n      Calls the superclass constructor with the SemanticScholar API URL.\n    \"\"\"\n    super().__init__(\"https://api.semanticscholar.org/graph/v1/paper/search\")\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.semantic_scholar_loader.SemanticScholarLoader.fetch_and_sort_papers","title":"<code>fetch_and_sort_papers(search_query, limit=100, top_n=20, year_range=None, keyword_combinations=None, weight_similarity=0.5)</code>","text":"<p>Fetches and sorts papers from the SemanticScholar API. Args:   search_query (str): The query to search for.   limit (int, optional): The maximum number of results to return. Defaults to 100.   top_n (int, optional): The maximum number of results to return after sorting. Defaults to 20.   year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None.   keyword_combinations (list, optional): A list of keyword combinations to search for. Defaults to None.   weight_similarity (float, optional): The weight to give to the similarity score when sorting. Defaults to 0.5. Returns:   list: A list of the top <code>top_n</code> paper objects sorted by combined score. Examples:</p> <p>fetch_and_sort_papers(\"machine learning\", limit=50, top_n=10, year_range=(2010, 2020))   [{...}, {...}, ...]</p> Source code in <code>autoresearcher/data_sources/web_apis/semantic_scholar_loader.py</code> <pre><code>def fetch_and_sort_papers(\n    self,\n    search_query,\n    limit=100,\n    top_n=20,\n    year_range=None,\n    keyword_combinations=None,\n    weight_similarity=0.5,\n):\n    \"\"\"\n    Fetches and sorts papers from the SemanticScholar API.\n    Args:\n      search_query (str): The query to search for.\n      limit (int, optional): The maximum number of results to return. Defaults to 100.\n      top_n (int, optional): The maximum number of results to return after sorting. Defaults to 20.\n      year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None.\n      keyword_combinations (list, optional): A list of keyword combinations to search for. Defaults to None.\n      weight_similarity (float, optional): The weight to give to the similarity score when sorting. Defaults to 0.5.\n    Returns:\n      list: A list of the top `top_n` paper objects sorted by combined score.\n    Examples:\n      &gt;&gt;&gt; fetch_and_sort_papers(\"machine learning\", limit=50, top_n=10, year_range=(2010, 2020))\n      [{...}, {...}, ...]\n    \"\"\"\n    papers = []\n    if keyword_combinations is None:\n        keyword_combinations = [search_query]\n\n    for combination in keyword_combinations:\n        papers.extend(self.fetch_data(combination, limit, year_range))\n\n    max_citations = max(papers, key=lambda x: x[\"citationCount\"])[\"citationCount\"]\n\n    for paper in papers:\n        similarity = jellyfish.jaro_similarity(search_query, paper[\"title\"])\n        normalized_citation_count = paper[\"citationCount\"] / max_citations\n        paper[\"combined_score\"] = (weight_similarity * similarity) + (\n            (1 - weight_similarity) * normalized_citation_count\n        )\n\n    sorted_papers = sorted(papers, key=lambda x: x[\"combined_score\"], reverse=True)\n\n    # deduplicate paper entries prior to taking top n results\n    sorted_dedup_papers = list(\n        {each_paper[\"paperId\"]: each_paper for each_paper in sorted_papers}.values()\n    )\n\n    return sorted_dedup_papers[:top_n]\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.semantic_scholar_loader.SemanticScholarLoader.fetch_data","title":"<code>fetch_data(search_query, limit=100, year_range=None)</code>","text":"<p>Fetches data from the SemanticScholar API. Args:   search_query (str): The query to search for.   limit (int, optional): The maximum number of results to return. Defaults to 100.   year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None. Returns:   list: A list of paper objects. Examples:</p> <p>fetch_data(\"machine learning\", limit=50, year_range=(2010, 2020))   [{...}, {...}, ...]</p> Source code in <code>autoresearcher/data_sources/web_apis/semantic_scholar_loader.py</code> <pre><code>def fetch_data(self, search_query, limit=100, year_range=None):\n    \"\"\"\n    Fetches data from the SemanticScholar API.\n    Args:\n      search_query (str): The query to search for.\n      limit (int, optional): The maximum number of results to return. Defaults to 100.\n      year_range (tuple, optional): A tuple of two integers representing the start and end year of the search. Defaults to None.\n    Returns:\n      list: A list of paper objects.\n    Examples:\n      &gt;&gt;&gt; fetch_data(\"machine learning\", limit=50, year_range=(2010, 2020))\n      [{...}, {...}, ...]\n    \"\"\"\n    params = {\n        \"query\": search_query,\n        \"limit\": limit,\n        \"fields\": \"title,url,abstract,authors,citationStyles,journal,citationCount,year,externalIds\",\n    }\n\n    if year_range is not None:\n        params[\"year\"] = year_range\n\n    data = self.make_request(\"\", params=params)\n    return data.get(\"data\", [])\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.base_web_api_data_loader.BaseWebAPIDataLoader","title":"<code>BaseWebAPIDataLoader</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>autoresearcher/data_sources/web_apis/base_web_api_data_loader.py</code> <pre><code>class BaseWebAPIDataLoader(ABC):\n    def __init__(self, base_url):\n        self.base_url = base_url\n\n    @abstractmethod\n    def fetch_data(self, search_query, **kwargs):\n        \"\"\"\n        Fetches data from the API.\n        Args:\n          search_query (str): The search query to use.\n          **kwargs: Additional keyword arguments to pass to the API.\n        Returns:\n          dict: The response from the API.\n        Raises:\n          NotImplementedError: If the method is not implemented.\n        \"\"\"\n        pass\n\n    def make_request(self, endpoint, params=None):\n        \"\"\"\n        Makes a request to the API.\n        Args:\n          endpoint (str): The API endpoint to make the request to.\n          params (dict, optional): Additional parameters to pass to the API. Defaults to None.\n        Returns:\n          dict: The response from the API.\n        Raises:\n          Exception: If the request fails.\n        \"\"\"\n        url = f\"{self.base_url}{endpoint}\"\n        response = requests.get(url, params=params)\n\n        if response.status_code == 200:\n            data = response.json()\n            return data\n        else:\n            raise Exception(f\"Failed to fetch data from API: {response.status_code}\")\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.base_web_api_data_loader.BaseWebAPIDataLoader.fetch_data","title":"<code>fetch_data(search_query, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Fetches data from the API. Args:   search_query (str): The search query to use.   **kwargs: Additional keyword arguments to pass to the API. Returns:   dict: The response from the API. Raises:   NotImplementedError: If the method is not implemented.</p> Source code in <code>autoresearcher/data_sources/web_apis/base_web_api_data_loader.py</code> <pre><code>@abstractmethod\ndef fetch_data(self, search_query, **kwargs):\n    \"\"\"\n    Fetches data from the API.\n    Args:\n      search_query (str): The search query to use.\n      **kwargs: Additional keyword arguments to pass to the API.\n    Returns:\n      dict: The response from the API.\n    Raises:\n      NotImplementedError: If the method is not implemented.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/data_sources/#autoresearcher.data_sources.web_apis.base_web_api_data_loader.BaseWebAPIDataLoader.make_request","title":"<code>make_request(endpoint, params=None)</code>","text":"<p>Makes a request to the API. Args:   endpoint (str): The API endpoint to make the request to.   params (dict, optional): Additional parameters to pass to the API. Defaults to None. Returns:   dict: The response from the API. Raises:   Exception: If the request fails.</p> Source code in <code>autoresearcher/data_sources/web_apis/base_web_api_data_loader.py</code> <pre><code>def make_request(self, endpoint, params=None):\n    \"\"\"\n    Makes a request to the API.\n    Args:\n      endpoint (str): The API endpoint to make the request to.\n      params (dict, optional): Additional parameters to pass to the API. Defaults to None.\n    Returns:\n      dict: The response from the API.\n    Raises:\n      Exception: If the request fails.\n    \"\"\"\n    url = f\"{self.base_url}{endpoint}\"\n    response = requests.get(url, params=params)\n\n    if response.status_code == 200:\n        data = response.json()\n        return data\n    else:\n        raise Exception(f\"Failed to fetch data from API: {response.status_code}\")\n</code></pre>"},{"location":"reference/llms/","title":"Llms","text":""},{"location":"reference/llms/#autoresearcher.llms.openai.openai_call","title":"<code>openai_call(prompt, use_gpt4=False, temperature=0.5, max_tokens=100)</code>","text":"<p>Calls OpenAI API to generate a response to a given prompt. Args:   prompt (str): The prompt to generate a response to.   use_gpt4 (bool, optional): Whether to use GPT-4o-mini or GPT-4o. Defaults to False.   temperature (float, optional): The temperature of the response. Defaults to 0.5.   max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 100. Returns:   str: The generated response. Examples:</p> <p>openai_call(\"Hello, how are you?\")   \"I'm doing great, thanks for asking!\" Notes:   The OpenAI API key must be set in the environment variable OPENAI_API_KEY.</p> Source code in <code>autoresearcher/llms/openai.py</code> <pre><code>def openai_call(\n    prompt: str, use_gpt4: bool = False, temperature: float = 0.5, max_tokens: int = 100\n):\n    \"\"\"\n    Calls OpenAI API to generate a response to a given prompt.\n    Args:\n      prompt (str): The prompt to generate a response to.\n      use_gpt4 (bool, optional): Whether to use GPT-4o-mini or GPT-4o. Defaults to False.\n      temperature (float, optional): The temperature of the response. Defaults to 0.5.\n      max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 100.\n    Returns:\n      str: The generated response.\n    Examples:\n      &gt;&gt;&gt; openai_call(\"Hello, how are you?\")\n      \"I'm doing great, thanks for asking!\"\n    Notes:\n      The OpenAI API key must be set in the environment variable OPENAI_API_KEY.\n    \"\"\"\n    if not use_gpt4:\n        # Call GPT-4o-mini model\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        response = openai.ChatCompletion.create(\n            model=\"gpt-4o-mini\",\n            messages=messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            top_p=1,\n            frequency_penalty=0,\n            presence_penalty=0,\n        )\n        return response.choices[0].message.content.strip()\n    else:\n        # Call GPT-4o model\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        response = openai.ChatCompletion.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            n=1,\n            stop=None,\n        )\n        return response.choices[0].message.content.strip()\n</code></pre>"},{"location":"reference/utils/","title":"Utils","text":""},{"location":"reference/utils/#autoresearcher.utils.count_tokens.count_tokens","title":"<code>count_tokens(text)</code>","text":"<p>Counts the number of tokens in a given text. Args:   text (str): The text to tokenize. Returns:   int: The number of tokens in <code>text</code>. Examples:</p> <p>count_tokens(\"This is a sentence.\")   6 Notes:   The encoding used is determined by the <code>tiktoken.encoding_for_model</code> function.</p> Source code in <code>autoresearcher/utils/count_tokens.py</code> <pre><code>def count_tokens(text):\n    \"\"\"\n    Counts the number of tokens in a given text.\n    Args:\n      text (str): The text to tokenize.\n    Returns:\n      int: The number of tokens in `text`.\n    Examples:\n      &gt;&gt;&gt; count_tokens(\"This is a sentence.\")\n      6\n    Notes:\n      The encoding used is determined by the `tiktoken.encoding_for_model` function.\n    \"\"\"\n    # encoding = tiktoken.get_encoding(\"cl100k_base\")\n    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n\n    tokens = encoding.encode(text)\n    return len(tokens)\n</code></pre>"},{"location":"reference/utils/#autoresearcher.utils.generate_keyword_combinations.generate_keyword_combinations","title":"<code>generate_keyword_combinations(research_question)</code>","text":"<p>Generates keyword combinations for a given research question. Args:   research_question (str): The research question to generate keyword combinations for. Returns:   list: A list of keyword combinations for the given research question. Examples:</p> <p>generate_keyword_combinations(\"What is the impact of AI on healthcare?\")   [\"AI healthcare\", \"impact AI healthcare\", \"AI healthcare impact\"]</p> Source code in <code>autoresearcher/utils/generate_keyword_combinations.py</code> <pre><code>def generate_keyword_combinations(research_question):\n    \"\"\"\n    Generates keyword combinations for a given research question.\n    Args:\n      research_question (str): The research question to generate keyword combinations for.\n    Returns:\n      list: A list of keyword combinations for the given research question.\n    Examples:\n      &gt;&gt;&gt; generate_keyword_combinations(\"What is the impact of AI on healthcare?\")\n      [\"AI healthcare\", \"impact AI healthcare\", \"AI healthcare impact\"]\n    \"\"\"\n    prompt = keyword_combination_prompt.format(research_question=research_question)\n    response = openai_call(prompt, use_gpt4=False, temperature=0, max_tokens=200)\n    combinations = response.split(\"\\n\")\n    return [\n        combination.split(\": \")[1]\n        for combination in combinations\n        if \": \" in combination\n    ]\n</code></pre>"},{"location":"reference/utils/#autoresearcher.utils.get_citations.get_citation_by_doi","title":"<code>get_citation_by_doi(doi)</code>","text":"<p>Retrieves a citation for a given DOI. Args:   doi (str): The DOI of the citation to retrieve. Returns:   str: The citation for the given DOI. Raises:   ValueError: If the response is not valid JSON. Notes:   Requires an email address to be set in the EMAIL environment variable. Examples:</p> <p>get_citation_by_doi(\"10.1038/s41586-020-2003-7\")   \"Liu, Y., Chen, X., Han, M., Li, Y., Li, L., Zhang, J., ... &amp; Zhang, Y. (2020). A SARS-CoV-2 protein interaction map reveals targets for drug repurposing. Nature, 581(7809), 561-570.\"</p> Source code in <code>autoresearcher/utils/get_citations.py</code> <pre><code>def get_citation_by_doi(doi):\n    \"\"\"\n    Retrieves a citation for a given DOI.\n    Args:\n      doi (str): The DOI of the citation to retrieve.\n    Returns:\n      str: The citation for the given DOI.\n    Raises:\n      ValueError: If the response is not valid JSON.\n    Notes:\n      Requires an email address to be set in the EMAIL environment variable.\n    Examples:\n      &gt;&gt;&gt; get_citation_by_doi(\"10.1038/s41586-020-2003-7\")\n      \"Liu, Y., Chen, X., Han, M., Li, Y., Li, L., Zhang, J., ... &amp; Zhang, Y. (2020). A SARS-CoV-2 protein interaction map reveals targets for drug repurposing. Nature, 581(7809), 561-570.\"\n    \"\"\"\n    url = f\"https://api.citeas.org/product/{doi}?email={EMAIL}\"\n    response = requests.get(url)\n    try:\n        data = response.json()\n        return data[\"citations\"][0][\"citation\"]\n    except ValueError:\n        return response.text\n</code></pre>"},{"location":"reference/workflows/","title":"Workflows","text":""},{"location":"reference/workflows/#autoresearcher.workflows.literature_review.combine_answers.combine_answers","title":"<code>combine_answers(answers, research_question, use_gpt4=False, temperature=0.1)</code>","text":"<p>Combines a list of answers into a concise literature review using OpenAI API. Args:   answers (list): A list of answers to combine.   research_question (str): The research question to use in the literature review.   use_gpt4 (bool, optional): Whether to use GPT-4 for the literature review. Defaults to False.   temperature (float, optional): The temperature to use for the OpenAI API. Defaults to 0.1. Returns:   str: The literature review. Examples:</p> <p>answers = [\"Answer 1\", \"Answer 2\"] research_question = \"What is the impact of AI on society?\" combine_answers(answers, research_question)   \"The impact of AI on society is significant. Answer 1...Answer 2...\"</p> Source code in <code>autoresearcher/workflows/literature_review/combine_answers.py</code> <pre><code>def combine_answers(answers, research_question, use_gpt4=False, temperature=0.1):\n    \"\"\"\n    Combines a list of answers into a concise literature review using OpenAI API.\n    Args:\n      answers (list): A list of answers to combine.\n      research_question (str): The research question to use in the literature review.\n      use_gpt4 (bool, optional): Whether to use GPT-4 for the literature review. Defaults to False.\n      temperature (float, optional): The temperature to use for the OpenAI API. Defaults to 0.1.\n    Returns:\n      str: The literature review.\n    Examples:\n      &gt;&gt;&gt; answers = [\"Answer 1\", \"Answer 2\"]\n      &gt;&gt;&gt; research_question = \"What is the impact of AI on society?\"\n      &gt;&gt;&gt; combine_answers(answers, research_question)\n      \"The impact of AI on society is significant. Answer 1...Answer 2...\"\n    \"\"\"\n    answer_list = \"\\n\\n\".join(answers)\n    prompt = literature_review_prompt.format(\n        research_question=research_question, answer_list=answer_list\n    )\n\n    # Calculate the tokens in the input\n    input_tokens = count_tokens(prompt)\n\n    # Calculate the remaining tokens for the response\n    remaining_tokens = 4080 - input_tokens\n    max_tokens = max(remaining_tokens, 0)\n    literature_review = openai_call(\n        prompt, use_gpt4=use_gpt4, temperature=temperature, max_tokens=max_tokens\n    )\n\n    return literature_review\n</code></pre>"},{"location":"reference/workflows/#autoresearcher.workflows.literature_review.literature_review.literature_review","title":"<code>literature_review(research_question, output_file=None, use_gpt4=False)</code>","text":"<p>Generates an academic literature review for a given research question. Args:   research_question (str): The research question to generate a literature review for.   output_file (str, optional): The file path to save the literature review to.   use_gpt4 (bool, optional): Whether to use GPT-4 for generating the literature review. Defaults to False. Returns:   str: The generated literature review. Examples:</p> <p>literature_review('What is the impact of AI on healthcare?')   Research question: What is the impact of AI on healthcare?   Auto Researcher initiated!   Generating keyword combinations...   Keyword combinations generated!   Fetching top 20 papers...   Top 20 papers fetched!   Extracting research findings from papers...   Research findings extracted!   Synthesizing answers...   Literature review generated!   Academic Literature Review: ...   References:   1. ...   Keyword combinations used to search for papers: 1. AI healthcare, 2. impact AI healthcare</p> Source code in <code>autoresearcher/workflows/literature_review/literature_review.py</code> <pre><code>def literature_review(research_question, output_file=None, use_gpt4=False):\n    \"\"\"\n    Generates an academic literature review for a given research question.\n    Args:\n      research_question (str): The research question to generate a literature review for.\n      output_file (str, optional): The file path to save the literature review to.\n      use_gpt4 (bool, optional): Whether to use GPT-4 for generating the literature review. Defaults to False.\n    Returns:\n      str: The generated literature review.\n    Examples:\n      &gt;&gt;&gt; literature_review('What is the impact of AI on healthcare?')\n      Research question: What is the impact of AI on healthcare?\n      Auto Researcher initiated!\n      Generating keyword combinations...\n      Keyword combinations generated!\n      Fetching top 20 papers...\n      Top 20 papers fetched!\n      Extracting research findings from papers...\n      Research findings extracted!\n      Synthesizing answers...\n      Literature review generated!\n      Academic Literature Review: ...\n      References:\n      1. ...\n      Keyword combinations used to search for papers: 1. AI healthcare, 2. impact AI healthcare\n    \"\"\"\n    SemanticScholar = SemanticScholarLoader()\n\n    print(\n        colored(\n            f\"Research question: {research_question}\", \"yellow\", attrs=[\"bold\", \"blink\"]\n        )\n    )\n    print(colored(\"Auto Researcher initiated!\", \"yellow\"))\n\n    # Generate keyword combinations\n    print(colored(\"Generating keyword combinations...\", \"yellow\"))\n    keyword_combinations = generate_keyword_combinations(research_question)\n    print(colored(\"Keyword combinations generated!\", \"green\"))\n\n    # Fetch the top 20 papers for the research question\n    search_query = research_question\n    print(colored(\"Fetching top 20 papers...\", \"yellow\"))\n    top_papers = SemanticScholar.fetch_and_sort_papers(\n        search_query, keyword_combinations=keyword_combinations, year_range=\"2000-2023\"\n    )\n    print(colored(\"Top 20 papers fetched!\", \"green\"))\n\n    # Extract answers and from the top 20 papers\n    print(colored(\"Extracting research findings from papers...\", \"yellow\"))\n    answers = extract_answers_from_papers(top_papers, research_question, use_gpt4=use_gpt4)\n    print(colored(\"Research findings extracted!\", \"green\"))\n\n    # Combine answers into a concise academic literature review\n    print(colored(\"Synthesizing answers...\", \"yellow\"))\n    literature_review = combine_answers(answers, research_question, use_gpt4=use_gpt4)\n    print(colored(\"Literature review generated!\", \"green\"))\n\n    # Extract citations from answers and append a references list to the literature review\n    citations = extract_citations(answers)\n    references_list = \"\\n\".join(\n        [f\"{idx + 1}. {citation}\" for idx, citation in enumerate(citations)]\n    )\n    literature_review += \"\\n\\nReferences:\\n\" + references_list\n\n    # Append the keyword combinations to the literature review\n    literature_review += \"\\n\\nKeyword combinations used to search for papers: \"\n    literature_review += \", \".join(\n        [f\"{i+1}. {combination}\" for i, combination in enumerate(keyword_combinations)]\n    )\n\n    # Print the academic literature review\n    print(colored(\"Academic Literature Review:\", \"cyan\"), literature_review, \"\\n\")\n\n    # Save the literature review to a file if the output_file argument is provided\n    if output_file:\n        with open(output_file, \"w\") as f:\n            f.write(literature_review)\n        print(colored(f\"Literature review saved to {output_file}\", \"green\"))\n\n    return literature_review\n</code></pre>"},{"location":"reference/workflows/#autoresearcher.workflows.literature_review.extract_answers_from_papers.extract_answers_from_papers","title":"<code>extract_answers_from_papers(papers, research_question, use_gpt4=False, temperature=0, max_tokens=150)</code>","text":"<p>Extracts answers from paper abstracts. Args:   papers (list): A list of papers.   research_question (str): The research question to answer.   use_gpt4 (bool, optional): Whether to use GPT-4 for answer extraction. Defaults to False.   temperature (float, optional): The temperature for GPT-4 answer extraction. Defaults to 0.   max_tokens (int, optional): The maximum number of tokens for GPT-4 answer extraction. Defaults to 150. Returns:   list: A list of answers extracted from the paper abstracts. Examples:</p> <p>extract_answers_from_papers(papers, research_question)   ['Answer 1 SOURCE: Citation 1', 'Answer 2 SOURCE: Citation 2']</p> Source code in <code>autoresearcher/workflows/literature_review/extract_answers_from_papers.py</code> <pre><code>def extract_answers_from_papers(\n    papers, research_question, use_gpt4=False, temperature=0, max_tokens=150\n):\n    \"\"\"\n    Extracts answers from paper abstracts.\n    Args:\n      papers (list): A list of papers.\n      research_question (str): The research question to answer.\n      use_gpt4 (bool, optional): Whether to use GPT-4 for answer extraction. Defaults to False.\n      temperature (float, optional): The temperature for GPT-4 answer extraction. Defaults to 0.\n      max_tokens (int, optional): The maximum number of tokens for GPT-4 answer extraction. Defaults to 150.\n    Returns:\n      list: A list of answers extracted from the paper abstracts.\n    Examples:\n      &gt;&gt;&gt; extract_answers_from_papers(papers, research_question)\n      ['Answer 1 SOURCE: Citation 1', 'Answer 2 SOURCE: Citation 2']\n    \"\"\"\n    answers = []\n    default_answer = \"No answer found.\"\n\n    for paper in papers:\n        abstract = paper.get(\"abstract\", \"\")\n        title = colored(paper.get(\"title\", \"\"), \"magenta\", attrs=[\"bold\"])\n        if \"externalIds\" in paper and \"DOI\" in paper[\"externalIds\"]:\n            citation = get_citation_by_doi(paper[\"externalIds\"][\"DOI\"])\n        else:\n            citation = paper[\"url\"]\n        prompt = extract_answer_prompt.format(\n            research_question=research_question, abstract=abstract\n        )\n        answer = openai_call(\n            prompt, use_gpt4=use_gpt4, temperature=temperature, max_tokens=max_tokens\n        )\n\n        print(f\"Processing paper: {title}\")\n\n        answer_with_citation = f\"{answer}\\n{citation}\"\n        if answer != default_answer:\n            answer_with_citation = f\"{answer} SOURCE: {citation}\"\n            answers.append(answer_with_citation)\n            print(colored(f\"Answer found!\", \"green\"))\n            print(colored(f\"{answer_with_citation}\", \"cyan\"))\n\n    return answers\n</code></pre>"},{"location":"reference/workflows/#autoresearcher.workflows.literature_review.extract_citations.extract_citations","title":"<code>extract_citations(answers)</code>","text":"<p>Extracts bibliographical citations from a list of answers. Args:   answers (list): A list of strings containing answers. Returns:   list: A list of strings containing bibliographical citations. Examples:</p> <p>answers = [\"This is an answer. SOURCE: Smith, J. (2020).\",   ...            \"This is another answer. SOURCE: Jones, A. (2021).\"] extract_citations(answers)   [\"Smith, J. (2020)\", \"Jones, A. (2021)\"]</p> Source code in <code>autoresearcher/workflows/literature_review/extract_citations.py</code> <pre><code>def extract_citations(answers):\n    \"\"\"\n    Extracts bibliographical citations from a list of answers.\n    Args:\n      answers (list): A list of strings containing answers.\n    Returns:\n      list: A list of strings containing bibliographical citations.\n    Examples:\n      &gt;&gt;&gt; answers = [\"This is an answer. SOURCE: Smith, J. (2020).\",\n      ...            \"This is another answer. SOURCE: Jones, A. (2021).\"]\n      &gt;&gt;&gt; extract_citations(answers)\n      [\"Smith, J. (2020)\", \"Jones, A. (2021)\"]\n    \"\"\"\n    citations = []\n    for answer in answers:\n        citation_start = answer.rfind(\"SOURCE: \")\n        if citation_start != -1:\n            citation = answer[citation_start + len(\"SOURCE: \") :]\n            citations.append(citation)\n    return citations\n</code></pre>"}]}